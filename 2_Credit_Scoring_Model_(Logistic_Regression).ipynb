{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6938d21a-23ad-42ce-9c0a-e97331f526b9",
   "metadata": {},
   "source": [
    "### **Step 1: Setting Up the Environment and Loading Artifacts**\n",
    "\n",
    "Before we begin, we will import the necessary libraries and load the configuration files (`config.json`) and tools (`preprocessor`, `kmeans`) that we saved from the previous segmentation project. This step ensures that this notebook is built upon the knowledge and logic of the first project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f722be-928b-460a-8015-8a80e877d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading artifacts from the segmentation project...\n",
      "Artifacts loaded successfully.\n",
      "\n",
      "Environment and helper functions are ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Core Libraries ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json, warnings, sklearn, sys\n",
    "from pathlib import Path\n",
    "from joblib import load\n",
    "\n",
    "# --- Scikit-learn Modules ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
    "\n",
    "# --- Notebook Settings ---\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.3f}\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# === 1) LOADING ARTIFACTS ===\n",
    "print(\"Loading artifacts from the segmentation project...\")\n",
    "art_dir = Path(\"artifacts\")\n",
    "cfg_path = art_dir / \"config.json\"\n",
    "preproc_path = art_dir / \"preprocessor_kmeans.joblib\"\n",
    "kmeans_path  = art_dir / \"kmeans_k3.joblib\"\n",
    "\n",
    "if not cfg_path.exists():\n",
    "    raise RuntimeError(\"`artifacts/config.json` not found. Please run the Export cell in the segmentation notebook first.\")\n",
    "\n",
    "with cfg_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    CFG = json.load(f)\n",
    "\n",
    "# We load these for consistency (good for version/schema checks even if not used directly)\n",
    "preproc_kmeans = load(preproc_path) if preproc_path.exists() else None\n",
    "kmeans_k3      = load(kmeans_path)  if kmeans_path.exists()  else None\n",
    "print(\"Artifacts loaded successfully.\")\n",
    "\n",
    "# Version warning (for informational purposes)\n",
    "cfg_skl = CFG.get(\"versions\", {}).get(\"sklearn\")\n",
    "if cfg_skl and cfg_skl.split(\".\")[:2] != sklearn.__version__.split(\".\")[:2]:\n",
    "    warnings.warn(f\"Warning: sklearn version mismatch. Trained with: {cfg_skl} | Current: {sklearn.__version__}. \"\n",
    "                  \"Minor version differences are usually fine, but pipeline behavior could change.\")\n",
    "\n",
    "# === 2) CONFIGURATION AND HELPER FUNCTION ===\n",
    "W_LOW   = CFG[\"winsor_low_bounds\"]\n",
    "W_HIGH  = CFG[\"winsor_high_bounds\"]\n",
    "WIN_COLS = CFG[\"winsor_cols\"]\n",
    "MODEL_INPUT_COLS = CFG[\"model_input_cols\"]\n",
    "CATEGORICAL_FEATURES = CFG.get(\"categorical_features\", [])\n",
    "NUMERIC_FEATURES     = CFG.get(\"numeric_features\", [])\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "# Safety check: do the main keys exist?\n",
    "assert isinstance(WIN_COLS, list) and isinstance(MODEL_INPUT_COLS, list), \"config.json is missing expected keys.\"\n",
    "\n",
    "def apply_winsor(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies winsorization using the same lower/upper bounds calculated in the segmentation notebook.\n",
    "    Object-type columns are converted to numeric; invalid values become NaN.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for c in WIN_COLS:\n",
    "        if c in df.columns:\n",
    "            lo, hi = W_LOW.get(c), W_HIGH.get(c)\n",
    "            if lo is not None and hi is not None:\n",
    "                df[c] = pd.to_numeric(df[c], errors=\"coerce\").clip(lower=lo, upper=hi)\n",
    "    return df\n",
    "\n",
    "print(\"\\nEnvironment and helper functions are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c42da-cebc-47f7-a461-6e36fd42b185",
   "metadata": {},
   "source": [
    "### **Step 2: Loading and Consistently Preparing the Data**\n",
    "\n",
    "In this critical step, we will load the raw `application_train.csv` data and prepare it for training our Logistic Regression model. The primary goal of this process is to ensure **100% consistency** with the previous segmentation project. This guarantees that both models operate on the same core assumptions and data structure, allowing them to be harmoniously integrated into the future Streamlit application.\n",
    "\n",
    "The operations in this cell are as follows:\n",
    "1.  **Efficient Loading:** Only the columns necessary for modeling will be loaded into memory using the `usecols` parameter.\n",
    "2.  **Anomaly Correction:** The nonsensical values in the `DAYS_EMPLOYED` column will be corrected to `NaN`, just as in the segmentation project.\n",
    "3.  **Feature Engineering:** New features (`AGE_YEARS`, `CREDIT_TO_INCOME_RATIO`, etc.) will be derived using the **exact same** formulas and `safe_div` function defined and used in the segmentation project.\n",
    "4.  **Schema Consistency:** By using the `MODEL_INPUT_COLS` list loaded from `config.json`, we will ensure that the model's input DataFrame matches the first project in terms of both column names and **order**.\n",
    "5.  **Outlier Management:** Outliers will be suppressed by calling the `apply_winsor` helper function with the **exact same lower and upper bounds** calculated in the first project.\n",
    "6.  **Data Type Adjustment:** The data type of categorical columns will be set to `category` to ensure they are correctly identified by the `preprocessor`.\n",
    "\n",
    "At the end of these steps, we will have a completely clean, consistent, and ready `X_lr` (features) and `y_lr` (target) dataset to train our Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0404a420-3a44-4326-ad45-7a372c902a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (307511, 14)\n",
      "Ready:\n",
      "X_lr shape: (307511, 17) | y_lr shape: (307511,)\n",
      "Sample rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>AGE_YEARS</th>\n",
       "      <th>YEARS_EMPLOYED</th>\n",
       "      <th>CREDIT_TO_INCOME_RATIO</th>\n",
       "      <th>ANNUITY_TO_INCOME_RATIO</th>\n",
       "      <th>EMPLOYED_TO_AGE_RATIO</th>\n",
       "      <th>CREDIT_TERM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>202,500.000</td>\n",
       "      <td>Working</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>406,597.500</td>\n",
       "      <td>24,700.500</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.139</td>\n",
       "      <td>25.921</td>\n",
       "      <td>1.745</td>\n",
       "      <td>2.008</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.067</td>\n",
       "      <td>16.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>270,000.000</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>1,293,502.500</td>\n",
       "      <td>35,698.500</td>\n",
       "      <td>0.622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.932</td>\n",
       "      <td>3.255</td>\n",
       "      <td>4.791</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.071</td>\n",
       "      <td>36.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>67,500.000</td>\n",
       "      <td>Working</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>135,000.000</td>\n",
       "      <td>6,750.000</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.730</td>\n",
       "      <td>52.181</td>\n",
       "      <td>0.616</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.012</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>135,000.000</td>\n",
       "      <td>Working</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>312,682.500</td>\n",
       "      <td>29,686.500</td>\n",
       "      <td>0.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.068</td>\n",
       "      <td>8.326</td>\n",
       "      <td>2.316</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.160</td>\n",
       "      <td>10.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>121,500.000</td>\n",
       "      <td>Working</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>513,000.000</td>\n",
       "      <td>21,865.500</td>\n",
       "      <td>0.323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.608</td>\n",
       "      <td>8.323</td>\n",
       "      <td>4.222</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.152</td>\n",
       "      <td>23.462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CODE_GENDER  CNT_CHILDREN    NAME_FAMILY_STATUS  \\\n",
       "0           M             0  Single / not married   \n",
       "1           F             0               Married   \n",
       "2           M             0  Single / not married   \n",
       "3           F             0        Civil marriage   \n",
       "4           M             0  Single / not married   \n",
       "\n",
       "             NAME_EDUCATION_TYPE  AMT_INCOME_TOTAL NAME_INCOME_TYPE  \\\n",
       "0  Secondary / secondary special       202,500.000          Working   \n",
       "1               Higher education       270,000.000    State servant   \n",
       "2  Secondary / secondary special        67,500.000          Working   \n",
       "3  Secondary / secondary special       135,000.000          Working   \n",
       "4  Secondary / secondary special       121,500.000          Working   \n",
       "\n",
       "  NAME_CONTRACT_TYPE    AMT_CREDIT  AMT_ANNUITY  EXT_SOURCE_2  EXT_SOURCE_3  \\\n",
       "0         Cash loans   406,597.500   24,700.500         0.263         0.139   \n",
       "1         Cash loans 1,293,502.500   35,698.500         0.622           NaN   \n",
       "2    Revolving loans   135,000.000    6,750.000         0.556         0.730   \n",
       "3         Cash loans   312,682.500   29,686.500         0.650           NaN   \n",
       "4         Cash loans   513,000.000   21,865.500         0.323           NaN   \n",
       "\n",
       "   AGE_YEARS  YEARS_EMPLOYED  CREDIT_TO_INCOME_RATIO  ANNUITY_TO_INCOME_RATIO  \\\n",
       "0     25.921           1.745                   2.008                    0.122   \n",
       "1     45.932           3.255                   4.791                    0.132   \n",
       "2     52.181           0.616                   2.000                    0.100   \n",
       "3     52.068           8.326                   2.316                    0.220   \n",
       "4     54.608           8.323                   4.222                    0.180   \n",
       "\n",
       "   EMPLOYED_TO_AGE_RATIO  CREDIT_TERM  \n",
       "0                  0.067       16.461  \n",
       "1                  0.071       36.234  \n",
       "2                  0.012       20.000  \n",
       "3                  0.160       10.533  \n",
       "4                  0.152       23.462  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Step 2: Load Data + Prepare Features (LR-compatible) ===\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RAW_PATH = \"data/application_train.csv\"\n",
    "\n",
    "# 1) Read the dataset (only required columns)\n",
    "base_cols = [\n",
    "    'TARGET','CODE_GENDER','CNT_CHILDREN','NAME_FAMILY_STATUS','NAME_EDUCATION_TYPE',\n",
    "    'DAYS_BIRTH','AMT_INCOME_TOTAL','NAME_INCOME_TYPE','DAYS_EMPLOYED',\n",
    "    'NAME_CONTRACT_TYPE','AMT_CREDIT','AMT_ANNUITY','EXT_SOURCE_2','EXT_SOURCE_3'\n",
    "]\n",
    "# A small trick to ensure EXT_SOURCE_3 is the last column if it exists, for consistency\n",
    "df_raw = pd.read_csv(RAW_PATH, usecols=[c for c in base_cols if c != 'EXT_SOURCE_3'] + ['EXT_SOURCE_3'])\n",
    "print(f\"Loaded: {df_raw.shape}\")\n",
    "\n",
    "# 2) Anomaly correction: DAYS_EMPLOYED = 365243 -> NaN\n",
    "df_raw['DAYS_EMPLOYED'] = df_raw['DAYS_EMPLOYED'].replace({365243: np.nan})\n",
    "\n",
    "# 3) Feature engineering (identical to segmentation)\n",
    "def safe_div(num, den):\n",
    "    num = pd.to_numeric(num, errors='coerce')\n",
    "    den = pd.to_numeric(den, errors='coerce')\n",
    "    out = np.where((den > 0) & np.isfinite(den) & np.isfinite(num), num / den, np.nan)\n",
    "    return pd.Series(out, index=num.index)\n",
    "\n",
    "df_feat = df_raw.copy()\n",
    "df_feat['AGE_YEARS']            = (-df_feat['DAYS_BIRTH'] / 365)\n",
    "df_feat['YEARS_EMPLOYED']       = (-df_feat['DAYS_EMPLOYED'] / 365)\n",
    "df_feat['CREDIT_TO_INCOME_RATIO']  = safe_div(df_feat['AMT_CREDIT'],  df_feat['AMT_INCOME_TOTAL'])\n",
    "df_feat['ANNUITY_TO_INCOME_RATIO'] = safe_div(df_feat['AMT_ANNUITY'], df_feat['AMT_INCOME_TOTAL'])\n",
    "df_feat['EMPLOYED_TO_AGE_RATIO']   = safe_div(df_feat['YEARS_EMPLOYED'], df_feat['AGE_YEARS'])\n",
    "df_feat['CREDIT_TERM']             = safe_div(df_feat['AMT_CREDIT'],  df_feat['AMT_ANNUITY'])  # ≈ term in years\n",
    "\n",
    "# 4) Create LR input table: Generate the MODEL_INPUT_COLS schema\n",
    "# (Came from the segmentation export — order & names will be identical)\n",
    "missing_in_feat = [c for c in MODEL_INPUT_COLS if c not in df_feat.columns]\n",
    "assert not missing_in_feat, f\"Missing feature(s): {missing_in_feat}\"\n",
    "\n",
    "X_lr = df_feat[MODEL_INPUT_COLS].copy()   # only model inputs\n",
    "y_lr = df_feat[TARGET_COL].astype(int)    # target\n",
    "\n",
    "# 5) Winsorization (using the same boundaries)\n",
    "X_lr = apply_winsor(X_lr)\n",
    "\n",
    "# 6) Data type setup (categorical/numerical)\n",
    "cat_cols = CFG.get(\"categorical_features\", [])\n",
    "num_cols = CFG.get(\"numeric_features\", [])\n",
    "for c in cat_cols:\n",
    "    if c in X_lr.columns:\n",
    "        X_lr[c] = X_lr[c].astype('category')\n",
    "\n",
    "print(\"Ready:\")\n",
    "print(f\"X_lr shape: {X_lr.shape} | y_lr shape: {y_lr.shape}\")\n",
    "print(\"Sample rows:\")\n",
    "display(X_lr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32431fc0-fbbc-4544-aa54-8d761b228410",
   "metadata": {},
   "source": [
    "### **Step 3: Creating Training and Test Sets**\n",
    "\n",
    "To objectively measure our model's performance, we need to split our dataset into two parts: a **training set**, which the model will learn from, and a **test set**, on which we will test its performance on data it has never seen before.\n",
    "\n",
    "In this imbalanced dataset, it is crucial to ensure that the `TARGET` variable (the default rate) is distributed proportionally in both sets. Therefore, we will perform the split using the `stratify` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ca9505-9334-4d8b-a1b0-b7b727b3fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (246008, 17)\n",
      "Test set shape:   (61503, 17)\n",
      "\n",
      "Original data default rate: 0.081\n",
      "Training set default rate:  0.081\n",
      "Test set default rate:    0.081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into 80% training and 20% test\n",
    "# stratify=y_lr -> Ensures that the default rate in both the train and test sets\n",
    "# is the same as in the original dataset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_lr, y_lr, \n",
    "    test_size=0.20, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y_lr\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape:   {X_test.shape}\\n\")\n",
    "print(f\"Original data default rate: {y_lr.mean():.3f}\")\n",
    "print(f\"Training set default rate:  {y_train.mean():.3f}\")\n",
    "print(f\"Test set default rate:    {y_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838a5e0-353a-4853-ae5b-425f4637ef1d",
   "metadata": {},
   "source": [
    "### **Step 4: Building the Preprocessing and Model Pipeline for Logistic Regression**\n",
    "\n",
    "Before training our Logistic Regression model, we will combine all the preprocessing steps and the model itself into a single `Pipeline` object. This approach prevents data leakage, keeps the code organized, and makes it easy to apply the model to new data later on.\n",
    "\n",
    "Our pipeline will include the following steps:\n",
    "1.  **Preprocessor:** A `ColumnTransformer` that will handle missing data imputation, scaling, and encoding separately for numerical and categorical columns.\n",
    "2.  **Model:** A `LogisticRegression` model configured with the `class_weight='balanced'` parameter to manage the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094c5250-78b1-46d1-bdd7-f1b8bba42b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression pipeline created successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  [&#x27;CNT_CHILDREN&#x27;,\n",
       "                                                   &#x27;AMT_INCOME_TOTAL&#x27;,\n",
       "                                                   &#x27;AMT_CREDIT&#x27;, &#x27;AMT_ANNUITY&#x27;,\n",
       "                                                   &#x27;EXT_SOURCE_2&#x27;,\n",
       "                                                   &#x27;EXT_SOURCE_3&#x27;, &#x27;AGE_YEARS&#x27;,\n",
       "                                                   &#x27;YEARS_EMPLOYED&#x27;,\n",
       "                                                   &#x27;CREDIT_TO_INCOME_RATIO&#x27;,\n",
       "                                                   &#x27;ANNUITY_TO_INCOME_RATIO&#x27;,\n",
       "                                                   &#x27;EMPLOYED_TO_AGE_R...\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;CODE_GENDER&#x27;,\n",
       "                                                   &#x27;NAME_FAMILY_STATUS&#x27;,\n",
       "                                                   &#x27;NAME_EDUCATION_TYPE&#x27;,\n",
       "                                                   &#x27;NAME_INCOME_TYPE&#x27;,\n",
       "                                                   &#x27;NAME_CONTRACT_TYPE&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
       "                                    random_state=42, solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  [&#x27;CNT_CHILDREN&#x27;,\n",
       "                                                   &#x27;AMT_INCOME_TOTAL&#x27;,\n",
       "                                                   &#x27;AMT_CREDIT&#x27;, &#x27;AMT_ANNUITY&#x27;,\n",
       "                                                   &#x27;EXT_SOURCE_2&#x27;,\n",
       "                                                   &#x27;EXT_SOURCE_3&#x27;, &#x27;AGE_YEARS&#x27;,\n",
       "                                                   &#x27;YEARS_EMPLOYED&#x27;,\n",
       "                                                   &#x27;CREDIT_TO_INCOME_RATIO&#x27;,\n",
       "                                                   &#x27;ANNUITY_TO_INCOME_RATIO&#x27;,\n",
       "                                                   &#x27;EMPLOYED_TO_AGE_R...\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;CODE_GENDER&#x27;,\n",
       "                                                   &#x27;NAME_FAMILY_STATUS&#x27;,\n",
       "                                                   &#x27;NAME_EDUCATION_TYPE&#x27;,\n",
       "                                                   &#x27;NAME_INCOME_TYPE&#x27;,\n",
       "                                                   &#x27;NAME_CONTRACT_TYPE&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
       "                                    random_state=42, solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, RobustScaler())]),\n",
       "                                 [&#x27;CNT_CHILDREN&#x27;, &#x27;AMT_INCOME_TOTAL&#x27;,\n",
       "                                  &#x27;AMT_CREDIT&#x27;, &#x27;AMT_ANNUITY&#x27;, &#x27;EXT_SOURCE_2&#x27;,\n",
       "                                  &#x27;EXT_SOURCE_3&#x27;, &#x27;AGE_YEARS&#x27;, &#x27;YEARS_EMPLOYED&#x27;,\n",
       "                                  &#x27;CREDIT_TO_INCOME_RATIO&#x27;,\n",
       "                                  &#x27;ANNUITY_TO_INCOME_RATIO&#x27;,\n",
       "                                  &#x27;EMPLOYED_TO_AGE_RATIO&#x27;, &#x27;CREDIT_TERM&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;CODE_GENDER&#x27;, &#x27;NAME_FAMILY_STATUS&#x27;,\n",
       "                                  &#x27;NAME_EDUCATION_TYPE&#x27;, &#x27;NAME_INCOME_TYPE&#x27;,\n",
       "                                  &#x27;NAME_CONTRACT_TYPE&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;CNT_CHILDREN&#x27;, &#x27;AMT_INCOME_TOTAL&#x27;, &#x27;AMT_CREDIT&#x27;, &#x27;AMT_ANNUITY&#x27;, &#x27;EXT_SOURCE_2&#x27;, &#x27;EXT_SOURCE_3&#x27;, &#x27;AGE_YEARS&#x27;, &#x27;YEARS_EMPLOYED&#x27;, &#x27;CREDIT_TO_INCOME_RATIO&#x27;, &#x27;ANNUITY_TO_INCOME_RATIO&#x27;, &#x27;EMPLOYED_TO_AGE_RATIO&#x27;, &#x27;CREDIT_TERM&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>RobustScaler</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.RobustScaler.html\">?<span>Documentation for RobustScaler</span></a></div></label><div class=\"sk-toggleable__content \"><pre>RobustScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;CODE_GENDER&#x27;, &#x27;NAME_FAMILY_STATUS&#x27;, &#x27;NAME_EDUCATION_TYPE&#x27;, &#x27;NAME_INCOME_TYPE&#x27;, &#x27;NAME_CONTRACT_TYPE&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content \"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['CNT_CHILDREN',\n",
       "                                                   'AMT_INCOME_TOTAL',\n",
       "                                                   'AMT_CREDIT', 'AMT_ANNUITY',\n",
       "                                                   'EXT_SOURCE_2',\n",
       "                                                   'EXT_SOURCE_3', 'AGE_YEARS',\n",
       "                                                   'YEARS_EMPLOYED',\n",
       "                                                   'CREDIT_TO_INCOME_RATIO',\n",
       "                                                   'ANNUITY_TO_INCOME_RATIO',\n",
       "                                                   'EMPLOYED_TO_AGE_R...\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['CODE_GENDER',\n",
       "                                                   'NAME_FAMILY_STATUS',\n",
       "                                                   'NAME_EDUCATION_TYPE',\n",
       "                                                   'NAME_INCOME_TYPE',\n",
       "                                                   'NAME_CONTRACT_TYPE'])])),\n",
       "                ('model',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=1000,\n",
       "                                    random_state=42, solver='liblinear'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Required libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# If the feature lists from config.json are empty, let's derive them automatically from X_lr.\n",
    "if not CATEGORICAL_FEATURES or not NUMERIC_FEATURES:\n",
    "    print(\"Warning: Feature lists from config.json are empty, deriving them automatically.\")\n",
    "    CATEGORICAL_FEATURES = X_lr.select_dtypes(include=['object','category']).columns.tolist()\n",
    "    NUMERIC_FEATURES     = X_lr.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# 1) Define the preprocessing steps for LR\n",
    "numeric_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "# Create a OneHotEncoder that works with both old and new versions of scikit-learn.\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
    "\n",
    "categorical_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", ohe) # We use the version-compatible ohe object here\n",
    "])\n",
    "\n",
    "# Combine these steps with ColumnTransformer\n",
    "preprocessor_lr = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_tf, NUMERIC_FEATURES),\n",
    "        (\"cat\", categorical_tf, CATEGORICAL_FEATURES),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# 2) Define the Logistic Regression model\n",
    "logreg = LogisticRegression(\n",
    "    solver=\"liblinear\",\n",
    "    class_weight=\"balanced\", # The most important parameter for imbalanced classes\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 3) Combine all steps into a single final Pipeline\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor_lr),\n",
    "    (\"model\", logreg)\n",
    "])\n",
    "\n",
    "print(\"\\nLogistic Regression pipeline created successfully.\")\n",
    "lr_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d3975-4a44-4662-be20-a7702205da1b",
   "metadata": {},
   "source": [
    "### **Step 5: Training the Model and Initial Performance Evaluation**\n",
    "\n",
    "We will now train the `lr_pipeline` we've built on the training data. Afterward, we will calculate the **AUC (Area Under Curve)** scores for both the training and test sets to see how well the model has learned and how well it generalizes to unseen data. This serves as a quick check for the model's baseline performance and to see if there are signs of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b33dd-bd07-4821-a95b-da9e89be6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Train the pipeline on the TRAINING data\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make probability predictions for the training and test sets\n",
    "y_train_pred_proba = lr_pipeline.predict_proba(X_train)[:, 1]\n",
    "y_test_pred_proba = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the AUC scores\n",
    "auc_train = roc_auc_score(y_train, y_train_pred_proba)\n",
    "auc_test = roc_auc_score(y_test, y_test_pred_proba)\n",
    "\n",
    "print(f\"Training Set AUC: {auc_train:.4f}\")\n",
    "print(f\"Test Set AUC    : {auc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d1735-9402-4067-b687-893f41afda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and PR curves\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "# Safety check: regenerate probabilities\n",
    "y_train_proba = lr_pipeline.predict_proba(X_train)[:, 1]\n",
    "y_test_proba  = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr, tpr, thr = roc_curve(y_test, y_test_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "prec, rec, thr_pr = precision_recall_curve(y_test, y_test_proba)\n",
    "pr_auc = average_precision_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"AUC (test): {roc_auc:.3f}\")\n",
    "print(f\"PR-AUC (test): {pr_auc:.3f}\")\n",
    "\n",
    "# ROC\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC (AUC={roc_auc:.3f})\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve – Test\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision–Recall\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(rec, prec, label=f\"PR (AUC={pr_auc:.3f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve – Test\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5eac8e-a650-4e82-9788-fe171e12720b",
   "metadata": {},
   "source": [
    "### Step 6.1: Interpreting the Performance Curves\n",
    "\n",
    "**ROC Curve (AUC = 0.732):**\n",
    "Our model's ROC curve on the test set lies significantly above the diagonal random guess line (AUC=0.5). An **AUC score of 0.732** indicates that the model's ability to distinguish between defaulting and non-defaulting customers is between \"acceptable\" and \"good.\"\n",
    "\n",
    "**Precision-Recall Curve (PR-AUC = 0.213):**\n",
    "In our imbalanced dataset, where the default rate is only about 8%, the PR curve provides a more honest measure of performance. In such a dataset, the baseline PR-AUC for a random guess is equal to the positive class ratio, which is approximately **0.08**. The **PR-AUC score of 0.213** achieved by our model shows that it performs **about 2.6 times better** than the random baseline. This proves that the model has meaningful discriminatory power in this challenging and imbalanced problem.\n",
    "\n",
    "**Industry Metrics (Gini & KS):**\n",
    "When examining metrics that are standard in credit risk modeling, we see that our model has a **Gini Coefficient = 0.464** (`2*AUC-1`) and a **Kolmogorov-Smirnov (KS) Statistic = 0.344** (`max(TPR-FPR)`). These scores confirm that the model has an acceptable level of discriminatory power from an industry standards perspective as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280763c-363e-4981-932e-02268407b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Best threshold: Youden's J (TPR - FPR) is maximized\n",
    "J = tpr - fpr\n",
    "best_idx = np.argmax(J)\n",
    "best_thr = thr[best_idx]\n",
    "print(f\"Best threshold (Youden's J): {best_thr:.4f}  | TPR={tpr[best_idx]:.3f}, FPR={fpr[best_idx]:.3f}\")\n",
    "\n",
    "# Classify based on the threshold\n",
    "y_test_pred = (y_test_proba >= best_thr).astype(int)\n",
    "\n",
    "# Confusion matrix & report\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"\\nConfusion Matrix (test):\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report (test):\")\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "\n",
    "# Simple visualization\n",
    "plt.figure(figsize=(4.5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix – Test\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f13f79-7655-4758-bd4d-05288df0c4e9",
   "metadata": {},
   "source": [
    "### Step 7.1: Interpreting the Optimal Threshold and Decision Analysis\n",
    "\n",
    "To convert the model's probability scores into a final business decision (\"approve\" / \"decline\"), the optimal threshold was determined to be **0.4689** using the **Youden's J** statistic, which best balances the True Positive and False Positive rates. This means that applications with a default probability higher than 46.89% will be classified as \"risky.\"\n",
    "\n",
    "The results obtained with this threshold are as follows:\n",
    "*   **Confusion Matrix:**\n",
    "    *   The model correctly identified **3,543** out of **4,965** customers who would default as \"risky\" (True Positives).\n",
    "    *   At this threshold, approximately **39.8%** of all applications are flagged as \"risky,\" potentially being routed to an additional review process.\n",
    "\n",
    "*   **Classification Report (Class 1 - Risky Customers):**\n",
    "    *   **Recall: 0.714** -> This is our model's greatest strength. It successfully **captures 71.4%** of the customers who would actually default. This means the bank can proactively identify a large portion of its potential losses.\n",
    "    *   **Precision: 0.145** -> This is the model's most important \"trade-off.\" Only **14.5%** of the customers flagged as \"risky\" by the model actually default. This shows that in order not to miss risky customers, we accept that some safe customers will also be subject to additional scrutiny.\n",
    "\n",
    "**Business Decision and Next Steps:** This model is highly valuable for a loss minimization strategy due to its high \"Recall\" rate. However, the low \"Precision\" rate suggests that any application flagged as \"risky\" should not be automatically declined but rather be directed to a more detailed manual review process.\n",
    "\n",
    "**Note:** In this analysis, a statistically optimal threshold was determined. In a real-world business scenario, this threshold should be adjusted to a lower or higher value based on the financial costs of False Negative (lost principal) and False Positive (lost profit) decisions, as well as the company's risk appetite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714f0bee-8363-47e0-8f10-2d8a4870a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients and feature names from the pipeline\n",
    "# (We are getting the expanded names after OHE)\n",
    "model = lr_pipeline.named_steps[\"model\"]\n",
    "preproc = lr_pipeline.named_steps[\"preprocessor\"]\n",
    "\n",
    "try:\n",
    "    feat_names = preproc.get_feature_names_out()\n",
    "except Exception:\n",
    "    # Crude name generation for older versions\n",
    "    feat_names = []\n",
    "    # Numerical\n",
    "    for c in NUMERIC_FEATURES:\n",
    "        feat_names.append(f\"num__{c}\")\n",
    "    # Categorical (full names may not be available as they are expanded by OHE)\n",
    "    for c in CATEGORICAL_FEATURES:\n",
    "        feat_names.append(f\"cat__{c}\")\n",
    "\n",
    "coefs = model.coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"feature\": feat_names, \"coef\": coefs})\n",
    "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
    "coef_df.sort_values(\"abs_coef\", ascending=False, inplace=True)\n",
    "\n",
    "top_n = 15\n",
    "top_df = coef_df.head(top_n).copy()\n",
    "print(f\"Top {top_n} most impactful features (by absolute coefficient):\")\n",
    "display(top_df[[\"feature\",\"coef\"]])\n",
    "\n",
    "# Barh chart\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(top_df[\"feature\"][::-1], top_df[\"coef\"][::-1])\n",
    "plt.xlabel(\"Coefficient (log-odds impact)\")\n",
    "plt.title(\"Logistic Regression – Most Impactful Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef20be-68a3-45b8-866d-81efa081586f",
   "metadata": {},
   "source": [
    "### Step 8.1: Interpreting Feature Importances\n",
    "\n",
    "One of the greatest advantages of our Logistic Regression model is our ability to clearly see which factors increase or decrease risk. Upon examining the model's coefficients, we have obtained results that are highly consistent with business logic:\n",
    "\n",
    "*   **Most Significant Factors Increasing Risk (Positive Coefficients):**\n",
    "    *   **Income Type - Unemployed (`NAME_INCOME_TYPE_Unemployed`):** As expected, being unemployed is the factor that most increases default risk.\n",
    "    *   **Education Level - Lower (`Lower secondary` / `Secondary`):** Lower levels of education are associated with higher risk.\n",
    "\n",
    "*   **Most Significant Factors Decreasing Risk (Negative Coefficients):**\n",
    "    *   **Education Level - Academic (`Academic degree`):** The highest level of education is the factor that most reduces risk.\n",
    "    *   **External Credit Scores (`EXT_SOURCE_2` / `EXT_SOURCE_3`):** High credit scores from external institutions strongly decrease the probability of default, as expected.\n",
    "\n",
    "**Methodological Note:** These coefficients should be interpreted relative to an implicit reference category, as `OneHotEncoder` creates a separate column for each category. For example, the effect of being 'Unemployed' is calculated relative to the average effect of all other income types. Additionally, coefficients for categories with very few samples (e.g., 'Student') may have less statistical power and should be interpreted with caution.\n",
    "\n",
    "These findings prove that our model makes decisions that are not only statistically sound but also logically consistent and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ded637-78b9-4c49-951f-e06c1b7dc973",
   "metadata": {},
   "source": [
    "### **Step 9: Testing Model Reliability - Probability Calibration**\n",
    "\n",
    "The quality of a credit scoring model is measured not only by its ability to correctly rank customers (AUC) but also by how well its predicted probabilities align with reality. The question, \"When the model says a group of customers is 20% risky, can we really expect 20% of them to default?\" probes the model's **calibration**. A well-calibrated model is a reliable tool that can be used directly in financial decisions.\n",
    "\n",
    "In this step, we will test how \"honest\" our model's probabilities are using two methods:\n",
    "1.  **Calibration (Reliability) Curve:** This graph compares the predicted probabilities against the actual default rates within those probability bins. The curve of a perfectly calibrated model should lie very close to the diagonal line.\n",
    "2.  **Brier Score:** This is a metric that summarizes both the model's accuracy and its calibration in a single number. The closer it is to 0, the better the model's probability predictions are.\n",
    "\n",
    "This analysis will show whether we can trust not only the model's ranking but also the probability scores it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5629f-1562-4af2-afbb-26b7bc75f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 9: Calibration Curve (Reliability) + Brier Score ===\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# Test set probabilities (generated in previous steps)\n",
    "y_prob = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 1) Calibration curve data\n",
    "frac_pos, mean_pred = calibration_curve(y_test, y_prob, n_bins=10, strategy=\"quantile\")\n",
    "\n",
    "# 2) Brier score (lower = better)\n",
    "brier = brier_score_loss(y_test, y_prob)\n",
    "print(f\"Brier Score (test): {brier:.4f}\")\n",
    "\n",
    "# 3) Plot\n",
    "plt.figure(figsize=(6.5, 5.5))\n",
    "plt.plot([0, 1], [0, 1], \"--\", label=\"Perfect Calibration\")\n",
    "plt.plot(mean_pred, frac_pos, marker=\"o\", label=\"Model\")\n",
    "plt.xlabel(\"Mean Predicted Probability (bin)\")\n",
    "plt.ylabel(\"Fraction of Positives (bin)\")\n",
    "plt.title(\"Calibration (Reliability) Curve – Test\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4) Bin-based table (a nice summary for the portfolio)\n",
    "calib_df = (pd.DataFrame({\"pred_mean\": mean_pred, \"true_rate\": frac_pos})\n",
    "              .assign(diff=lambda d: d[\"true_rate\"] - d[\"pred_mean\"]))\n",
    "print(\"Calibration table (bin averages):\")\n",
    "display(calib_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9369eb-8245-473d-ba89-1466ffb34502",
   "metadata": {},
   "source": [
    "### Step 9.1: Testing Model Reliability - Initial Calibration Analysis\n",
    "\n",
    "The quality of a credit scoring model is measured not only by its ability to correctly rank customers (AUC) but also by how well its predicted probabilities align with reality. The question, \"When the model says a group of customers is 20% risky, can we really expect 20% of them to default?\" probes the model's **calibration**.\n",
    "\n",
    "**Initial Analysis Results:**\n",
    "*   **Calibration Curve:** In the graph above, it is clear that our model's curve (orange) is consistently below the perfect calibration line (blue). This indicates that the probabilities predicted by our model are **systematically higher** than the actually observed default rates. Our model has a tendency to **overestimate** risk and be \"overly cautious.\"\n",
    "*   **Brier Score (0.2082):** This score, which is desired to be close to 0, numerically reflects this deviation in the probability predictions and confirms that the model's calibration is poor.\n",
    "\n",
    "**Identified Problem:**\n",
    "Although our model is successful at **ranking** customers by risk, the probability scores it produces are **not reliable** enough to be used directly in financial calculations (e.g., Expected Loss). To solve this problem, we will apply a post-hoc calibration technique in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcfddf3-2680-4f78-8485-e058b1ff3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 9.2: Probability Calibration (Isotonic) – Version-compatible ===\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import (brier_score_loss, roc_auc_score, precision_recall_curve,\n",
    "                             average_precision_score, roc_curve)\n",
    "\n",
    "# 1) 5-fold isotonic calibration (based on the pipeline)\n",
    "try:\n",
    "    cal_lr = CalibratedClassifierCV(estimator=lr_pipeline, method=\"isotonic\", cv=5)\n",
    "except TypeError:\n",
    "    # For older scikit-learn versions\n",
    "    cal_lr = CalibratedClassifierCV(base_estimator=lr_pipeline, method=\"isotonic\", cv=5)\n",
    "\n",
    "cal_lr.fit(X_train, y_train)\n",
    "\n",
    "# 2) Compare raw and calibrated probabilities on the test set\n",
    "p_raw = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "p_cal = cal_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# AUC and PR-AUC\n",
    "fpr_raw, tpr_raw, _ = roc_curve(y_test, p_raw)\n",
    "fpr_cal, tpr_cal, _ = roc_curve(y_test, p_cal)\n",
    "auc_raw, auc_cal = roc_auc_score(y_test, p_raw), roc_auc_score(y_test, p_cal)\n",
    "\n",
    "prec_raw, rec_raw, _ = precision_recall_curve(y_test, p_raw)\n",
    "prec_cal, rec_cal, _ = precision_recall_curve(y_test, p_cal)\n",
    "pr_auc_raw, pr_auc_cal = average_precision_score(y_test, p_raw), average_precision_score(y_test, p_cal)\n",
    "\n",
    "# Brier and calibration curve\n",
    "brier_raw = brier_score_loss(y_test, p_raw)\n",
    "brier_cal = brier_score_loss(y_test, p_cal)\n",
    "frac_raw, mean_raw = calibration_curve(y_test, p_raw, n_bins=10, strategy=\"quantile\")\n",
    "frac_cal, mean_cal = calibration_curve(y_test, p_cal, n_bins=10, strategy=\"quantile\")\n",
    "\n",
    "print(f\"AUC raw={auc_raw:.3f} | cal={auc_cal:.3f}\")\n",
    "print(f\"PR-AUC raw={pr_auc_raw:.3f} | cal={pr_auc_cal:.3f}\")\n",
    "print(f\"Brier raw={brier_raw:.4f} | cal={brier_cal:.4f}\")\n",
    "\n",
    "# Calibration plot\n",
    "plt.figure(figsize=(6.5,5.5))\n",
    "plt.plot([0,1],[0,1],\"--\",label=\"Perfect\")\n",
    "plt.plot(mean_raw, frac_raw, \"o-\", label=\"Model (raw)\")\n",
    "plt.plot(mean_cal, frac_cal, \"o-\", label=\"Model (calibrated)\")\n",
    "plt.xlabel(\"Mean predicted probability (bin)\"); plt.ylabel(\"Actual fraction of positives (bin)\")\n",
    "plt.title(\"Calibration Curve – Test\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a6e31-d9ed-4847-8724-f664d121fa02",
   "metadata": {},
   "source": [
    "### **Step 9.2: Correcting Probabilities (Isotonic Calibration Results)**\n",
    "\n",
    "To solve the calibration issue identified in the previous step, we applied a **post-hoc calibration** step using **isotonic regression** with `scikit-learn`'s `CalibratedClassifierCV` tool. The goal of this method is to align the model's probabilities with real-world data while preserving its ranking power.\n",
    "\n",
    "**Correction Results:**\n",
    "The calibration process was highly successful:\n",
    "*   **Calibration Curve:** In the comparative graph above, our \"Model (calibrated)\" line (green) almost **perfectly overlaps** with the \"Perfect Calibration\" line (blue). This is visual proof that the model now produces \"honest\" and reliable probabilities.\n",
    "*   **Brier Score:** The **Brier Score's drop from 0.2082 to 0.0693** after calibration numerically confirms that the overall error in the probability predictions has dramatically decreased.\n",
    "*   **Ranking Performance:** The fact that the **AUC (0.732)** and **PR-AUC (0.212)** scores remained virtually unchanged after calibration shows that we achieved this improvement while **preserving** the model's fundamental discriminatory power.\n",
    "\n",
    "**Final Outcome:**\n",
    "With this additional step, we have developed a credit scoring model that not only ranks well but also produces **probability estimates that are reliable and can be used directly as input for financial modeling**, making it ready for a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da681b60-d39a-467a-9cb8-d636e90f733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, confusion_matrix, classification_report\n",
    "\n",
    "p_cal = cal_lr.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thr = roc_curve(y_test, p_cal)\n",
    "J = tpr - fpr\n",
    "best = J.argmax()\n",
    "best_thr = thr[best]\n",
    "print(f\"Calibrated model best threshold (Youden): {best_thr:.4f} | TPR={tpr[best]:.3f}, FPR={fpr[best]:.3f}\")\n",
    "\n",
    "y_pred_cal = (p_cal >= best_thr).astype(int)\n",
    "print(confusion_matrix(y_test, y_pred_cal))\n",
    "print(classification_report(y_test, y_pred_cal, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5575e1-6dff-4050-98c2-f718489e25fb",
   "metadata": {},
   "source": [
    "### **Step 9.3: The Impact of Calibration on Business Decisions**\n",
    "\n",
    "Calibrating probabilities does more than just make the graphs look better; it also directly affects the model's final decision-making mechanism. To see the practical consequences of calibration, we determined a **new optimal threshold based on the calibrated probabilities** using the Youden's J method and compared the results with the decisions made using the raw model's threshold.\n",
    "\n",
    "**Comparative Analysis (Raw Model → Calibrated Model):**\n",
    "\n",
    "*   **Optimal Threshold Value:** `0.4689` → **`0.0817`**\n",
    "    *   **Interpretation:** This is the most striking change. Our new threshold has dropped to a level very close to the actual default rate in the dataset (8.1%). This is the strongest evidence that the calibrated probabilities now reflect real-world probabilities.\n",
    "\n",
    "*   **False Positive Rate:** `0.370` → **`0.323`**\n",
    "    *   **Business Impact:** This is our most significant gain. Thanks to calibration, **our rate of incorrectly flagging a safe customer as \"risky\" has noticeably decreased.** In concrete terms, **2,655 fewer** safe customers will be unnecessarily subjected to additional review. This increases operational efficiency and preserves customer satisfaction.\n",
    "\n",
    "*   **Risky Customer Capture Rate (Recall / TPR):** `0.714` → **`0.665`**\n",
    "    *   **Business Impact (The Trade-off):** This improvement came at a cost. Our capture rate for customers who would actually default has slightly decreased. This means that approximately **239 additional** risky customers might be missed.\n",
    "\n",
    "**Final Decision and Strategy:**\n",
    "The calibration process has provided us with a more balanced model. It significantly reduces false alarms (FP) while making a reasonable trade-off in our power to capture risky customers (TP).\n",
    "\n",
    "Which model to use (raw or calibrated) depends on the company's risk appetite:\n",
    "*   **Strategy A (Aggressive Risk Prevention):** A company that says, \"I don't want to miss a single risky customer,\" might prefer the **raw model** with its higher Recall rate.\n",
    "*   **Strategy B (Balanced Growth):** A company that says, \"I want to both manage risk and avoid turning away good customers,\" should prefer the **calibrated model** with its lower False Positive rate.\n",
    "\n",
    "This analysis shows that model calibration is not just a technical improvement but also a critical decision that directly impacts business strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8113cc8-3068-4e15-ad2c-cce56df5075d",
   "metadata": {},
   "source": [
    "### **Step 10: Exporting Final Model Artifacts and Performance Card**\n",
    "\n",
    "In this final step of our Logistic Regression project, we will export the model itself and all the important information documenting its performance into a reusable and portable format. This ensures the model's results are reproducible and creates a foundational \"Model Card\" to be used in future applications (like the Streamlit simulation) or in model performance monitoring processes.\n",
    "\n",
    "In this step, the following \"artifacts\" will be created and saved to the `artifacts/` folder:\n",
    "\n",
    "1.  **Models and Threshold:**\n",
    "    *   `logreg_calibrated.joblib`: The final, calibrated model that produces reliable probabilities.\n",
    "    *   `threshold.json`: The optimal threshold value used to convert probabilities into an \"approve/decline\" decision.\n",
    "    \n",
    "2.  **Performance Card (`metrics.json`):**\n",
    "    *   An easy-to-read summary file containing all the critical performance metrics of the model on the test set (AUC, PR-AUC, Gini, KS, Confusion Matrix values, etc.).\n",
    "\n",
    "3.  **Supporting Analysis Files:**\n",
    "    *   `lr_coefficients.csv`: The table of coefficients, critical for interpretability, showing which features the model uses to make decisions.\n",
    "    *   `calibration_bins.csv`: The calibration table, which shows how reliable the model's probabilities are.\n",
    "\n",
    "These files conclude this phase of the project and package all the knowledge of the developed model in an organized manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec615fc0-d94a-4b2d-9501-4e98660f0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "from pathlib import Path\n",
    "Path(\"artifacts\").mkdir(exist_ok=True)\n",
    "dump(cal_lr, \"artifacts/logreg_calibrated.joblib\")\n",
    "dump(lr_pipeline, \"artifacts/logreg_raw.joblib\")  # you can save both if you like\n",
    "with open(\"artifacts/threshold.json\",\"w\") as f:\n",
    "    import json; json.dump({\"youden_threshold\": float(best_thr)}, f, indent=2)\n",
    "print(\"Saved: logreg_calibrated.joblib, threshold.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b134391-c5ea-4175-8c25-e298d9a9f79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90f280-91f8-4208-84e8-2c0c3192a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 10: Export Metrics & Supporting Files ===\n",
    "from pathlib import Path\n",
    "from joblib import dump\n",
    "import json, numpy as np, pandas as pd\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "Path(\"artifacts\").mkdir(exist_ok=True)\n",
    "\n",
    "# 1) Test probabilities (raw/calibrated)\n",
    "p_raw = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "p_cal = cal_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 2) AUC / PR-AUC\n",
    "auc_raw = roc_auc_score(y_test, p_raw)\n",
    "auc_cal = roc_auc_score(y_test, p_cal)\n",
    "pr_raw  = average_precision_score(y_test, p_raw)\n",
    "pr_cal  = average_precision_score(y_test, p_cal)\n",
    "\n",
    "# 3) Secure the Youden threshold (from calibrated probabilities)\n",
    "fpr, tpr, thr = roc_curve(y_test, p_cal)\n",
    "J = tpr - fpr\n",
    "best = int(np.argmax(J))\n",
    "best_thr = float(thr[best])\n",
    "tpr_b, fpr_b = float(tpr[best]), float(fpr[best])\n",
    "\n",
    "# 4) Confusion matrix @ best_thr\n",
    "y_pred_cal = (p_cal >= best_thr).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred_cal)\n",
    "tn, fp, fn, tp = map(int, cm.ravel())\n",
    "\n",
    "# 5) Gini & KS\n",
    "gini = 2*auc_cal - 1\n",
    "ks   = float(np.max(tpr - fpr))\n",
    "\n",
    "# 6) Calibration bin table (calibrated)\n",
    "frac_cal, mean_cal = calibration_curve(y_test, p_cal, n_bins=10, strategy=\"quantile\")\n",
    "cal_df = (pd.DataFrame({\"pred_mean\": mean_cal, \"true_rate\": frac_cal})\n",
    "            .assign(diff=lambda d: d.true_rate - d.pred_mean))\n",
    "cal_df.to_csv(\"artifacts/calibration_bins.csv\", index=False)\n",
    "\n",
    "# 7) LR coefficients (from the raw LR for interpretability)\n",
    "preproc = lr_pipeline.named_steps[\"preprocessor\"]\n",
    "feat_names = preproc.get_feature_names_out()\n",
    "coefs = lr_pipeline.named_steps[\"model\"].coef_.ravel()\n",
    "coef_df = (pd.DataFrame({\"feature\": feat_names, \"coef\": coefs})\n",
    "             .assign(abs_coef=lambda d: d[\"coef\"].abs())\n",
    "             .sort_values(\"abs_coef\", ascending=False))\n",
    "coef_df.to_csv(\"artifacts/lr_coefficients.csv\", index=False)\n",
    "\n",
    "# 8) Metrics JSON\n",
    "metrics = {\n",
    "    \"auc_raw\": round(auc_raw, 3),\n",
    "    \"auc_cal\": round(auc_cal, 3),\n",
    "    \"prauc_raw\": round(pr_raw, 3),\n",
    "    \"prauc_cal\": round(pr_cal, 3),\n",
    "    \"gini\": round(gini, 3),\n",
    "    \"ks\": round(ks, 3),\n",
    "    \"threshold_youden\": best_thr,\n",
    "    \"tpr_at_threshold\": round(tpr_b, 3),\n",
    "    \"fpr_at_threshold\": round(fpr_b, 3),\n",
    "    \"confusion_matrix\": {\"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp}\n",
    "}\n",
    "with open(\"artifacts/metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  - artifacts/calibration_bins.csv\")\n",
    "print(\"  - artifacts/lr_coefficients.csv\")\n",
    "print(\"  - artifacts/metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995ed739-2a0b-408a-ae05-203ec9be64e7",
   "metadata": {},
   "source": [
    "### **Step 11: Smoke Test - Verifying the Artifacts**\n",
    "\n",
    "Before moving on to the next development phase (the Streamlit application), we will conduct one final \"smoke test\" to confirm that all the files (artifacts) we just saved are correct, uncorrupted, and working as expected.\n",
    "\n",
    "The purpose of this test is simple:\n",
    "1.  Load the saved calibrated model (`logreg_calibrated.joblib`) and the threshold value (`threshold.json`) from scratch.\n",
    "2.  Take a few random customer samples from the test set and run a prediction process with these loaded artifacts.\n",
    "3.  Check whether the outputs (probabilities and final decisions) are generated meaningfully and without errors.\n",
    "\n",
    "The successful completion of this test is the strongest proof that the files in our `artifacts/` folder are fully ready to be integrated into the Streamlit application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbc005-bffb-4862-b753-f5e75313bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 11: Smoke test (reload) ===\n",
    "from joblib import load\n",
    "import json\n",
    "\n",
    "cal_loaded = load(\"artifacts/logreg_calibrated.joblib\")\n",
    "with open(\"artifacts/threshold.json\", \"r\") as f:\n",
    "    thr_cfg = json.load(f)\n",
    "thr = float(thr_cfg[\"youden_threshold\"])\n",
    "\n",
    "# Test on 5 samples using the same winsor function\n",
    "X_sample = X_test.iloc[:5].copy()\n",
    "X_sample_w = apply_winsor(X_sample)\n",
    "p = cal_loaded.predict_proba(X_sample_w)[:, 1]\n",
    "pred = (p >= thr).astype(int)\n",
    "out = pd.DataFrame({\"prob\": p, \"pred\": pred, \"y_true\": y_test.iloc[:5].values})\n",
    "display(out)\n",
    "print(\"Reload smoke test OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f2948-ce51-4e3f-8f82-56692e5f9917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
